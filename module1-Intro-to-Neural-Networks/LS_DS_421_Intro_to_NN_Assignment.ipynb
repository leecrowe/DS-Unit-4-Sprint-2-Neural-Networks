{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: \n",
    "Where input is provided to the neural network; the features and bias of the data.\n",
    "### Hidden Layer: \n",
    "Where the neural network is actually implemented and the processing is done.\n",
    "### Output Layer: \n",
    "Where the result of all that work is provided.\n",
    "### Neuron: \n",
    "Where a calculation is done that is one part of the greater whole.\n",
    "### Weight: \n",
    "Like the slope in a linear function; how much should we care about a specific feature.\n",
    "### Activation Function: \n",
    "Determines how much signal (information) to pass onto the next node (step) in the network.\n",
    "### Node Map: \n",
    "A graph that shows the basic process of a given neural network.\n",
    "### Perceptron: \n",
    "The most basic neural network? Takes in however many features are given and provides a result based on that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "Input is provided based on the number of features for the problem being considered. A bias is also given to the network as an additional input. These inputs are then weighted (randomly at first) by being multiplied by the given weight and then put through the activation function. Here they are checked for error, the weights are updated, and the process (epoch) happens again for however many times it was set to. After each epoch an output is made and passed back into the network if it's still running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "for i in range(len(df)):\n",
    "    inputs.append([df.iloc[i,0], df.iloc[i,1], 1])\n",
    "inputs = np.array(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_output = []\n",
    "for i in range(len(df)):\n",
    "    target_output.append([df.iloc[i,2]])\n",
    "target_output = np.array(target_output)\n",
    "target_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87952478],\n",
       "       [-0.17372304],\n",
       "       [-0.14080298]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random weights (bias)\n",
    "weights = 2* np.random.random((3,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18540174],\n",
       "       [-0.4218148 ],\n",
       "       [ 0.06623458],\n",
       "       [-0.54098197]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate weighted sum\n",
    "weighted_sum = np.dot(inputs, weights)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54621812],\n",
       "       [0.39608257],\n",
       "       [0.51655259],\n",
       "       [0.36795918]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 training epoch to get initial predictions\n",
    "activated_output = sigmoid(weighted_sum)\n",
    "activated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45378188],\n",
       "       [ 0.60391743],\n",
       "       [ 0.48344741],\n",
       "       [-0.36795918]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get error\n",
    "error = target_output - activated_output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24786389],\n",
       "       [0.23920117],\n",
       "       [0.24972601],\n",
       "       [0.23256522]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_deriv(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11247614],\n",
       "       [ 0.14445776],\n",
       "       [ 0.12072939],\n",
       "       [-0.08557451]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magic of backprop\n",
    "adjustments = error * sigmoid_deriv(weighted_sum)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run it MANY times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0\n",
      "Weights after training\n",
      "[[-0.75630852]\n",
      " [-0.09282784]\n",
      " [ 0.24747417]]\n",
      "Output after training\n",
      "[[0.4648573 ]\n",
      " [0.26496356]\n",
      " [0.42201038]\n",
      " [0.23253524]]\n",
      "=========================\n",
      "Iteration #500\n",
      "Weights after training\n",
      "[[-5.84298127]\n",
      " [-5.84296991]\n",
      " [ 8.82796983]]\n",
      "Output after training\n",
      "[[0.99985259]\n",
      " [0.95180343]\n",
      " [0.95180395]\n",
      " [0.05437193]]\n",
      "=========================\n",
      "Iteration #1000\n",
      "Weights after training\n",
      "[[-7.21289511]\n",
      " [-7.21289472]\n",
      " [10.87508622]]\n",
      "Output after training\n",
      "[[0.99998102]\n",
      " [0.97494237]\n",
      " [0.97494238]\n",
      " [0.0279308 ]]\n",
      "=========================\n",
      "Iteration #1500\n",
      "Weights after training\n",
      "[[-8.02511404]\n",
      " [-8.02511399]\n",
      " [12.09084256]]\n",
      "Output after training\n",
      "[[0.99999438]\n",
      " [0.98312764]\n",
      " [0.98312764]\n",
      " [0.01873016]]\n",
      "=========================\n",
      "Iteration #2000\n",
      "Weights after training\n",
      "[[-8.60330807]\n",
      " [-8.60330806]\n",
      " [12.95685545]]\n",
      "Output after training\n",
      "[[0.99999764]\n",
      " [0.98729592]\n",
      " [0.98729592]\n",
      " [0.01407395]]\n",
      "=========================\n",
      "Iteration #2500\n",
      "Weights after training\n",
      "[[-9.05226556]\n",
      " [-9.05226556]\n",
      " [13.62952842]]\n",
      "Output after training\n",
      "[[0.99999879]\n",
      " [0.98981762]\n",
      " [0.98981762]\n",
      " [0.01126641]]\n",
      "=========================\n",
      "Iteration #3000\n",
      "Weights after training\n",
      "[[-9.4192046]\n",
      " [-9.4192046]\n",
      " [14.17943  ]]\n",
      "Output after training\n",
      "[[0.9999993 ]\n",
      " [0.99150622]\n",
      " [0.99150622]\n",
      " [0.0093903 ]]\n",
      "=========================\n",
      "Iteration #3500\n",
      "Weights after training\n",
      "[[-9.72945179]\n",
      " [-9.72945179]\n",
      " [14.64443972]]\n",
      "Output after training\n",
      "[[0.99999956]\n",
      " [0.99271554]\n",
      " [0.99271554]\n",
      " [0.0080486 ]]\n",
      "=========================\n",
      "Iteration #4000\n",
      "Weights after training\n",
      "[[-9.99817014]\n",
      " [-9.99817014]\n",
      " [15.04724707]]\n",
      "Output after training\n",
      "[[0.99999971]\n",
      " [0.99362405]\n",
      " [0.99362405]\n",
      " [0.00704169]]\n",
      "=========================\n",
      "Iteration #4500\n",
      "Weights after training\n",
      "[[-10.23515716]\n",
      " [-10.23515716]\n",
      " [ 15.40251789]]\n",
      "Output after training\n",
      "[[0.9999998 ]\n",
      " [0.99433145]\n",
      " [0.99433145]\n",
      " [0.00625828]]\n",
      "=========================\n",
      "Iteration #5000\n",
      "Weights after training\n",
      "[[-10.44710962]\n",
      " [-10.44710962]\n",
      " [ 15.72027908]]\n",
      "Output after training\n",
      "[[0.99999985]\n",
      " [0.9948978 ]\n",
      " [0.9948978 ]\n",
      " [0.00563146]]\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# Steps we've already done: \n",
    "# 1. Randomly Initialized Weights. Those are in memory as `weights`\n",
    "# 2. We've already got inputs data & target_output\n",
    "\n",
    "for iteration in range(5001):\n",
    "    \n",
    "    # Weighted sum\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activated output\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Error\n",
    "    error = target_output - activated_output\n",
    "    \n",
    "    # Adjustments\n",
    "    adjustments = error * sigmoid_deriv(activated_output)\n",
    "    \n",
    "    # Update weight\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "\n",
    "    if (iteration % 500) == 0:\n",
    "        print(f\"Iteration #{iteration}\")\n",
    "        \n",
    "        print(\"Weights after training\")\n",
    "        print(weights)\n",
    "\n",
    "        print(\"Output after training\")\n",
    "        print(activated_output)\n",
    "        \n",
    "        print(\"=\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03355237, 0.82762513, 0.40262844, ..., 0.18789327, 0.00350622,\n",
       "        0.27960308],\n",
       "       [0.008424  , 0.71604034, 0.55598426, ..., 0.22407851, 0.00295683,\n",
       "        0.26114412],\n",
       "       [0.04039768, 0.92409698, 0.32318146, ..., 0.11765825, 0.00339341,\n",
       "        0.16159073],\n",
       "       ...,\n",
       "       [0.02691539, 0.65135243, 0.38758161, ..., 0.14103664, 0.00131885,\n",
       "        0.16149234],\n",
       "       [0.00665306, 0.83828547, 0.39918356, ..., 0.20025708, 0.00232192,\n",
       "        0.31269379],\n",
       "       [0.00791454, 0.73605211, 0.55401772, ..., 0.24060198, 0.00249308,\n",
       "        0.18203439]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "norm = Normalizer()\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "print(feats)\n",
    "\n",
    "feat_df = diabetes[feats]\n",
    "feat_df.head()\n",
    "\n",
    "norm_array = norm.transform(feat_df)\n",
    "norm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((768,1))\n",
    "#ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((norm_array, ones))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target_df = diabetes['Outcome']\n",
    "target_array = np.array(diabetes['Outcome'])\n",
    "target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 768)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 * np.random.random((X.shape[1],1)) - 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, niter = 11):\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = self.__sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        y = y.reshape((y.shape[0],1))\n",
    "        \n",
    "        # Randomly Initialize Weights\n",
    "        weights = 2 * np.random.random((X.shape[1],1)) - 1\n",
    "        print(weights)\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            # Weighted sum of inputs / weights\n",
    "            weighted_sum = np.dot(X, weights)\n",
    "\n",
    "            # Activate!\n",
    "            activated_output = self.__sigmoid(weighted_sum)\n",
    "            print(f\"Predictions after loop {i}: \\n\", activated_output[:5])\n",
    "            print(\"=\"*20)\n",
    "\n",
    "            # Calc error\n",
    "            error = y - activated_output\n",
    "#            print(\"Error: \", error[:10])\n",
    "\n",
    "            # Update the Weights\n",
    "            adjustments = error * self.__sigmoid_derivative(activated_output)\n",
    "            weights += np.dot(X.T, adjustments)\n",
    "        \n",
    "#             if (i % 2) == 0:\n",
    "#                 print(f\"Iteration #{i}\")\n",
    "\n",
    "#                 print(\"Weights after training\")\n",
    "#                 print(weights)\n",
    "\n",
    "#                 print(\"Output after training\")\n",
    "#                 print(activated_output[:10])\n",
    "\n",
    "#                 print(\"=\"*25)\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return activated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6468957 ]\n",
      " [ 0.47111287]\n",
      " [ 0.71503598]\n",
      " [ 0.64281916]\n",
      " [-0.64339978]\n",
      " [ 0.4376066 ]\n",
      " [-0.12292621]\n",
      " [ 0.36580894]\n",
      " [-0.55870422]]\n",
      "Predictions after loop 0: \n",
      " [[0.60043481]\n",
      " [0.62737987]\n",
      " [0.54779989]\n",
      " [0.46409166]\n",
      " [0.40313948]]\n",
      "====================\n",
      "Predictions after loop 1: \n",
      " [[2.16518068e-25]\n",
      " [1.53230860e-25]\n",
      " [6.60686015e-25]\n",
      " [4.72273499e-24]\n",
      " [1.56024570e-22]]\n",
      "====================\n",
      "Predictions after loop 2: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "====================\n",
      "Predictions after loop 3: \n",
      " [[2.53012460e-51]\n",
      " [7.22768812e-52]\n",
      " [4.43174127e-50]\n",
      " [8.50028701e-50]\n",
      " [1.19132405e-46]]\n",
      "====================\n",
      "Predictions after loop 4: \n",
      " [[0.99624849]\n",
      " [0.9637371 ]\n",
      " [0.99938099]\n",
      " [0.99997542]\n",
      " [0.99999952]]\n",
      "====================\n",
      "Predictions after loop 5: \n",
      " [[1.16401723e-75]\n",
      " [1.58612801e-76]\n",
      " [9.07086564e-74]\n",
      " [4.83084216e-74]\n",
      " [2.00877021e-69]]\n",
      "====================\n",
      "Predictions after loop 6: \n",
      " [[1.22174159e-22]\n",
      " [5.83223359e-24]\n",
      " [3.30454140e-21]\n",
      " [2.31167065e-20]\n",
      " [3.49631677e-17]]\n",
      "====================\n",
      "Predictions after loop 7: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "====================\n",
      "Predictions after loop 8: \n",
      " [[1.42766766e-48]\n",
      " [2.75098407e-50]\n",
      " [2.21661609e-46]\n",
      " [4.16069586e-46]\n",
      " [2.66960918e-41]]\n",
      "====================\n",
      "Predictions after loop 9: \n",
      " [[0.99999333]\n",
      " [0.99901239]\n",
      " [0.99999988]\n",
      " [0.99999999]\n",
      " [1.        ]]\n",
      "====================\n",
      "Predictions after loop 10: \n",
      " [[1.17877463e-73]\n",
      " [1.07800732e-75]\n",
      " [8.39705148e-71]\n",
      " [5.11763250e-71]\n",
      " [1.09843675e-64]]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "prediction = Perceptron().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20816008],\n",
       "       [0.20129959],\n",
       "       [0.21268791],\n",
       "       [0.19363333],\n",
       "       [0.21632943],\n",
       "       [0.2103207 ],\n",
       "       [0.20495601],\n",
       "       [0.28968107],\n",
       "       [0.22294085],\n",
       "       [0.18273171]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77877749],\n",
       "       [-0.63054588],\n",
       "       [-0.70452722],\n",
       "       [-0.4348241 ],\n",
       "       [-0.36045161],\n",
       "       [ 0.96548652],\n",
       "       [ 0.34849157],\n",
       "       [-0.0807118 ],\n",
       "       [-0.6316217 ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 2 * np.random.random((X.shape[1],1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = np.dot(X, weights)\n",
    "weighted_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activated_output = sigmoid(weighted_sum)\n",
    "activated_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = y.reshape((y.shape[0],1)) - activated_output\n",
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjustments = error * sigmoid_deriv(activated_output)\n",
    "adjustments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.02786018],\n",
       "       [54.93544737],\n",
       "       [21.94450496],\n",
       "       [ 6.6622127 ],\n",
       "       [29.15823382],\n",
       "       [13.8312346 ],\n",
       "       [ 0.56945234],\n",
       "       [13.6481393 ],\n",
       "       [78.30535319]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights += np.dot(X.T, adjustments)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape((y.shape[0],1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
